{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gelybb33/Examenes-Gely/blob/main/Examen_DS_Maria_Becerril_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e051462",
      "metadata": {
        "id": "2e051462"
      },
      "source": [
        "# Examene DS  â€“ Maria Becerril Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51491930",
      "metadata": {
        "id": "51491930"
      },
      "source": [
        "\n",
        "## 1) Teorema de Bayes: explicaciÃ³n y ejemplo\n",
        "\n",
        "Explica con tus palabras el teorema de Bayes y da un ejemplo de cÃ³mo lo aplicarÃ­as en un problema de clasificaciÃ³n.\n",
        "\n",
        "**Respuesta original :**\n",
        "\n",
        "Probabilidad de un evento dado que ocurriÃ³ otro o una serie de eventos\n",
        "\n",
        "\\(P(ð‘—/ð’™)=(ð‘ƒ(ð‘—)ð‘ƒ(ð’™|ð‘—))/ð‘ƒ(ð’™)\\)\n",
        "\n",
        "\\(ð‘ƒ(ð’™|ð‘—)=\\) Probabilidad de x dado que el evento j suceda  \n",
        "\\(P(ð‘—/ð’™)=\\) Probabilidad de que j ocurra dado que x sucede  \n",
        "\\(P(x)=\\) Probabilidad de que x ocurra  \n",
        "\\(P(j)=\\) Probabilidad de que j ocurra  \n",
        "\n",
        "**Ejemplo:**  \n",
        "Queremos saber la probabilidad de que los enfermos de gripa e influenza puedan tener o no sintomas.\n",
        "\n",
        "P (y= sintomatico, x= Gripa & Influenza) = .6 \\*.5\\*.25 = .075  \n",
        "P (y= asintomatico, x= Gripa & Influenza) = .4 \\* .6 \\* .2 = .048  \n",
        "P(x= Gripa & Influenza) = .075 + .048 = .123  \n",
        "P (y= sintomatico, x= Gripa & Influenza) = .075 / .123 = .61  \n",
        "P (y= asintomatico, x= Gripa & Influenza) .048 / .123 = .39  \n",
        "\n",
        "Existe un 61% de que los enfermos de Gripa e Influenza tengan sÃ­ntomas, y un 39% de que los enfermos de Gripa e Influenza sean asintomÃ¡ticos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "754c7435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754c7435",
        "outputId": "807bafb8-9bdf-4af7-fe6a-cb9f09c2edc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(y=sintomÃ¡tico | x=gripa&influenza) = 0.61\n",
            "P(y=asintomÃ¡tico | x=gripa&influenza) = 0.39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo  - BAYES\n",
        "p_sym = 0.6\n",
        "p_gripa = 0.5\n",
        "p_infl = 0.25\n",
        "p_asym = 0.4\n",
        "p_gripa_alt = 0.6\n",
        "p_infl_alt = 0.2\n",
        "\n",
        "p_yx_sym = p_sym * p_gripa * p_infl      # 0.075\n",
        "p_yx_asym = p_asym * p_gripa_alt * p_infl_alt  # 0.048\n",
        "p_x = p_yx_sym + p_yx_asym               # 0.123\n",
        "\n",
        "post_sym = p_yx_sym / p_x\n",
        "post_asym = p_yx_asym / p_x\n",
        "\n",
        "print(\"P(y=sintomÃ¡tico | x=gripa&influenza) =\", round(post_sym, 3))\n",
        "print(\"P(y=asintomÃ¡tico | x=gripa&influenza) =\", round(post_asym, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b9bc10",
      "metadata": {
        "id": "c6b9bc10"
      },
      "source": [
        "\n",
        "## 2) DeserciÃ³n universitaria con sensibilidad/especificidad\n",
        "\n",
        " En una universidad, el 2% de los estudiantes desertan en el primer semestre. Un modelo de riesgo detecta correctamente a un desertor con probabilidad 0.9 (sensibilidad) y a un no desertor con probabilidad 0.8 (especificidad).  \n",
        "\n",
        "**a) Â¿CuÃ¡l es la probabilidad de que un estudiante clasificado como desertor realmente lo sea?**\n",
        "\n",
        "Estamos buscando la tasa verdaderos positivos, siendo el desertor  \n",
        "P(cd|d) = .9  \n",
        "P(d)=.02  \n",
        "P(dÂ¬) = .98  \n",
        "P(cd)= Probabilidad clasificado como desertor\n",
        "\n",
        "P(d|cd)= Probabilidad de un desertor dado que se clasifico como desertor  \n",
        "\\(P(d|cd)=(P(cd|d)P(d))/(P(cdâ”‚d)P(d)+ P(cdâ”‚dÂ¬)P(dÂ¬) )\\)\n",
        "\n",
        "\\(P(dâ”‚cd) =(.9 \\* .02)/((.9 \\* .02)+(.2 \\* .098) )= .018/.214\\)  \n",
        "**\\(P(d|cd) = 0.084\\)**\n",
        "\n",
        "**b) InterpretaciÃ³n :**  \n",
        "Existe un 8.4% de probabilidad de que un estudiante que ha sido clasificado como desertor lo sea; es decir que, tomando como target a los desertores, la tasa de clasificaciÃ³n de verdaderos positivas es muy baja. Aunque la sensibilidad (detecciÃ³n correcta de desertores reales) y especificidad (detecciÃ³n correcta de los que no desertan) del modelo (.9 & .8) son datos realmente altos. AquÃ­ como opciÃ³n no descartarÃ­a el modelo, y propondrÃ­a si bien ya no se puede aumentar la tasa de verdaderos positivos lo optarÃ­a para obtener los falsos positivos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589aa562",
      "metadata": {
        "id": "589aa562"
      },
      "source": [
        "\n",
        "## 3) Â¿CuÃ¡ndo usar a priori uniforme vs. estimarla con histÃ³rico?\n",
        "\n",
        "CuÃ¡ndo usar apriori uniforme?  \n",
        "Basandonos del concepto donde la a priori uniforme significa que asignamos la misma probabilidad a todos los valores posibles del parÃ¡metro dentro de un rango definido. Por lo que se usa cuando no se tiene informaciÃ³n previa. TambiÃ©n se puede optar por su uso cuando el target se encuentra equilibrado esperas la misma probabilidad de resultado en cualquier valor que pueda tomar.\n",
        "\n",
        "Cuando conviene estimarla con informaciÃ³n histÃ³rica?  \n",
        "Cuando se tiene informaciÃ³n histÃ³rica representativa y verdadera se optarÃ­a por estimarla, para estabilizar estimaciones, asÃ­ mismo el histÃ³rico puede ayudar a entender fluctuaciones o eventos atÃ­picos en la informaciÃ³n que sean recurrentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1caa9843",
      "metadata": {
        "id": "1caa9843"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ejemplo adicional  Beta-Binomial con prior uniforme vs. informada\n",
        "import numpy as np\n",
        "\n",
        "alpha_u, beta_u = 1, 1    # prior uniforme Beta(1,1)\n",
        "alpha_i, beta_i = 101, 4901  # prior histÃ³rica su media usando los parÃ¡metros ~2%\n",
        "\n",
        "obs_pos, obs_neg = 2, 98  # observaciones nuevas\n",
        "\n",
        "post_u = (alpha_u+obs_pos, beta_u+obs_neg)\n",
        "post_i = (alpha_i+obs_pos, beta_i+obs_neg)\n",
        "\n",
        "mean_u = (post_u[0])/(post_u[0]+post_u[1])\n",
        "mean_i = (post_i[0])/(post_i[0]+post_i[1])\n",
        "\n",
        "print(\"Posterior media con prior uniforme  :\", round(mean_u, 4))\n",
        "print(\"Posterior media con prior histÃ³rica :\", round(mean_i, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e705cca2",
      "metadata": {
        "id": "e705cca2"
      },
      "source": [
        "\n",
        "## 4) K-Fold vs. LOO vs. Hold-out\n",
        "K-fold: Partes los datos en k, entrenas k veces validando cada fold y promedias al ultimo.\n",
        "mantener la proporcion de k-folds en los que se divide\n",
        "Tiene variantes con aplicaciones para grupos y series d etiempo\n",
        "MÃ¡s estable y costoso.\n",
        "LOO: Muestras muy pequeÃ±as con varianza alta, puede tener costos computacionales altos\n",
        "Quieres minimizar el sesgo del estimador de error tomando en cuenta que tu varianza aumentara\n",
        "No usarlo cuando el modelo es no lineal.\n",
        "Poco sesgo pero alta varianza.\n",
        "Hold-out: Es rÃ¡pido y para datasets grandes.\n",
        "Hacer estratificacion para clasificaciÃ³n desbalanceada.\n",
        "Si te preocupa el efecto en la varianza puedes hacer multiples split y promedio para ponderarla.\n",
        "MÃ¡s rapido pero ruidoso.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6190fa87",
      "metadata": {
        "id": "6190fa87"
      },
      "source": [
        "\n",
        "## 5) MÃ©tricas y mejora sin perder interpretabilidad\n",
        "\n",
        "Accuracy = 92%  \n",
        "Precision(+) = 50%  \n",
        "Recall(+) = 20% Los Falsos negativos  \n",
        "Aunque en primera instancia tiene un accuracy alto, tenemos un 20% detectar los Verdaderos positivos, por lo que se tiene un 80% de detectar los Falsos negativos  \n",
        "La precisiÃ³n 50 nos dice que la mitad de los casos que se marcaron como positivos realmente eran positivo\n",
        "\n",
        "2. Â¿CÃ³mo mejoro sin perder interpretabilidad?  \n",
        "Como subir el recall, sin perder interpretabilidad?  \n",
        "Utilizar otra mÃ©trica de validaciÃ³n adecuada como PR-AUC Ã¡rea bajo la curva no accuracy. PR-AUC resume esa curva en un solo nÃºmero: cuanto mÃ¡s alto, mejor el modelo para mantener alta precisiÃ³n cuando empujas el recall.  \n",
        "Para dar mÃ¡s peso a la clase positiva usamos class_weight=\"balanced\".  \n",
        "â€¢  Ajuste de umbral (post-entrenamiento): no uses 0.5 por defecto.  \n",
        "â€¢  Bajar el umbral : etiquetas mÃ¡s casos como positivos â‡’ sube el recall (TPR) y tambiÃ©n suben los FP (baja la precisiÃ³n, sube FPR, baja especificidad).  \n",
        "â€¢  Subir el umbral : etiquetas menos casos como positivos â‡’ baja el recall, pero suele subir la precisiÃ³n. El umbral es tu palanca directa sobre el recall. Bajar el umbral aumenta recall (a costa de mÃ¡s FP); elige el punto operativo con una regla explÃ­cita\n",
        "\n",
        "Re-muestreo o Resampling: Al re-balancear el train (haciendo la clase positiva menos rara), el modelo â€œveâ€ mÃ¡s ejemplos positivos (o equivalentes ponderados) y baja el umbral interno para etiquetar 1 â‡’ detecta mÃ¡s verdaderos positivos â‡’ â†‘ recall (aunque suele bajar algo la precisiÃ³n).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee94948",
      "metadata": {
        "id": "3ee94948"
      },
      "source": [
        "\n",
        "## 6) Imagina que entrenaste un modelo de regresiÃ³n logÃ­stica y obtienes una curva ROC con un AUC de 0.78. a) QuÃ© significa este valor en tÃ©rminos de discriminaciÃ³n.\n",
        "\n",
        "QuÃ© significa AUC = 0.78?  \n",
        "Como sabemos el ROCâ€“AUC en logÃ­stica mide quÃ© tan bien el modelo ordena positivos por encima de negativos para todos los umbrales. Existe un 78% de probabilidad de que un positivo real reciba un score mayor que un negativo aleatorio. Tomando que el valor aleatorio por default, es un 50% de probabilidad de que discrimine un positivo real de un negativo, interpreto que esta sobre el aleatorio y es una buena regla.\n",
        "\n",
        "**b) Umbral Ã³ptimo por costos :**  \n",
        "Minimiza el costo esperado en validaciÃ³n usando TPR/FPR para cada umbral:  \n",
        "\\(Costo(Ï„) = Ï€Â·C_{FN}Â·(1âˆ’TPR(Ï„)) + (1âˆ’Ï€)Â·C_{FP}Â·FPR(Ï„)\\)  \n",
        "Ï€ = prevalencia (P(y=1)) medida en tu val original  \n",
        "Recorres los umbrales, calculas TPR/FPR y eliges el Ï„ que minimiza ese costo.  \n",
        "Equivalente geomÃ©trico en la ROC: usa iso-cost lines con pendiente  \n",
        "\\(m = (C_{FP}Â·(1âˆ’Ï€)) / (C_{FN}Â·Ï€)\\)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496cc3a1",
      "metadata": {
        "id": "496cc3a1"
      },
      "source": [
        "\n",
        "## 7) RegresiÃ³n lineal mÃºltiple vs. regularizada (Ridge/Lasso)\n",
        "\n",
        "1) RegresiÃ³n lineal mÃºltiple (OLS)  \n",
        "Estimadores insesgados bajo supuestos clÃ¡sicos (linealidad, homocedasticidad, no multicolinealidad fuerte).  \n",
        "Varianza alta si hay pocas observaciones, muchos predictores o multicolinealidad.  \n",
        "Poca colinealidad  \n",
        "Se usa cuando tienes pocos predictores, bien elegidos, con baja colinealidad, y un n grande.\n",
        "\n",
        "2) RegresiÃ³n regularizada  \n",
        "**Ridge (L2)**  \n",
        "Efecto: Busca disminuir coeficientes a 0, sin llegar a 0.  \n",
        "Reduce varianza y mejora generalizaciÃ³n.  \n",
        "Excelente con muchos predictores correlacionados (estabiliza al â€œrepartirâ€ peso entre ellos).  \n",
        "Se puede usar cuando se tiene una correlaciÃ³n alta entre variables y no puedes decidir que variable dejar o quieres usar varias variable correlacioandas  \n",
        "Quieres estabilidad mÃ¡s que selecciÃ³n estricta de variables.\n",
        "\n",
        "**Lasso (L1)**  \n",
        "Ãštil cuando hay muchos predictores irrelevantes.  \n",
        "Con predictores muy correlacionados, Lasso tiende a elegir uno y descartar el resto  \n",
        "Se usa cuando queremos reducir el conjunto de variables a un subconjunto mas pequeÃ±o.  \n",
        "TambiÃ©n si comportamientos raros y muchos de ellos son ruido\n",
        "\n",
        "**Ejemplos:**  \n",
        "##Ejemplo regresiÃ³n multiple:\n",
        "Tienes pocas variables, no hay multicolinealidad, Lo puedes usar para predecir las entradas de personas a un restaurante, usando si tienen hijos, si comen o cenan (variables que no esten correlacionadas y un data set chico ..)\n",
        "##Ejemplo regresiÃ³n lasso:\n",
        "Cuando tienes data sets mas grandes y quieres discriminar por las que contienen mayor informaciÃ³n para el modelo, ejemplo tienes 100 variables en un base del inegi para saber el nivel de endeudamiento, con lasso puedes discriminar esto.\n",
        "##Ejemplo regresiÃ³n Ridge:\n",
        "Quieres conocer por que en una competencia de nado los participantes son mas veloces, y tienes variables como estatura, peso, edad que generalmente estÃ¡n correlacionadas, con ridge puedes dejarlas en el modelo ..\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d21e68d",
      "metadata": {
        "id": "6d21e68d"
      },
      "source": [
        "\n",
        "## 8) Error en train vs. validation\n",
        "a) Â¿QuÃ© estÃ¡ ocurriendo?  \n",
        "Con training error = 0.02 y validation error = 0.30 estamos diciendo que el modleo comete un error del 2% con los datos, Ã³sea casi 0 error y luego el error de la validaciÃ³n aumenta un 30%, por lo que lo traduzco que tiene excelente interpretaciÃ³n para el set de entrenamiento, lo que ocasiono una mala interpretaciÃ³n para el set de validaciÃ³n o general.\n",
        "\n",
        "b) Â¿QuÃ© acciones tomar para corregirlo?  \n",
        "Revisar que no haya una variable que me este generando ruido, artificial, o algun input realizado anteriormente.  \n",
        "â€¢  Usar un modelo mÃ¡s simple (menos parÃ¡metros, regularizaciÃ³n).  \n",
        "â€¢  Aumentar datos de entrenamiento.  \n",
        "â€¢  Aplicar tÃ©cnicas como cross-validation, early stopping, dropout (en redes), etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8765653c",
      "metadata": {
        "id": "8765653c"
      },
      "source": [
        "\n",
        "## 9) Trade-off sesgoâ€“varianza\n",
        "\n",
        "QuÃ© es el trade-off sesgoâ€“varianza?  \n",
        "El sesgo es el error sistemÃ¡tico por usar un modelo demasiado simple o mal especificado (subajuste). Y la varianza es que tanto pueden cambiar las predicciones si reentrenas con diferentes muestras; suele crecer con modelos muy complejos.  \n",
        "El trade-off entre sesgo y varianza consiste en mantener un equilibrio ya que si bajas el sesgo se sube la varianza por lo que el objetivo es buscar un intermedio.\n",
        "\n",
        "SeÃ±ales prÃ¡cticas  \n",
        "subajuste: alto sesgo, error alto en train y valid; curvas de aprendizaje planas.  \n",
        "sobreajuste: alta varianza, error train bajo, pero  valid notablemente peor.\n",
        "\n",
        "**Ejemplo  (educaciÃ³n):**  \n",
        "Supongamos que queremos predecir si un estudiante aprobarÃ¡ un curso en funciÃ³n de:\n",
        "â€¢\tHoras de estudio por semana\n",
        "â€¢\tAsistencia a clase\n",
        "â€¢\tEntrega de tareas\n",
        "**Caso 1: Modelo con alto sesgo**\n",
        "Usamos una regresiÃ³n lineal con solo una variable (horas de estudio).\n",
        "â€¢\tEl modelo depende de las horas de estudio unicamnete para predecir, dejando afuera mÃ¡s variables\n",
        "â€¢\tResultado: hace predicciones muy generales\n",
        "â€¢\tProblema: subajuste â†’ muchas predicciones incorrectas.\n",
        "**Caso 2: Modelo con alta varianza**\n",
        "Usamos un Ã¡rbol de decisiÃ³n muy profundo que memoriza cada combinaciÃ³n de horas, asistencia y tareas. Osea se esta sobreajustando y repitiendo muchas veces la misma informaciÃ³n.\n",
        "â€¢\tEn el train, predice perfecto.\n",
        "â€¢\tPero en test, falla mucho porque memorizÃ³ los datos en lugar de aprender el patrÃ³n general.\n",
        "â€¢\tProblema: sobreajuste â†’ baja generalizaciÃ³n.\n",
        "**Caso Ideal con Varianza y sesgo ajustado**\n",
        "Usamos un Ã¡rbol de decisiÃ³n podado o un Random Forest con pocos niveles.\n",
        "â€¢\tUsando todas las variables para interpretar (horas de estudio + asistencia + tareas)\n",
        "â€¢\tResultado esperado: error bajo en train y en valid/test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69829e80",
      "metadata": {
        "id": "69829e80"
      },
      "source": [
        "\n",
        "## 10) Solo accuracy vs. mÃ©tricas orientadas a decisiÃ³n\n",
        "\n",
        "Si bien el accuracy es muy Ãºtil para la predicciÃ³n del modelo, le explicarÃ­a que existen otras mÃ©tricas orientadas a decisiÃ³n como  Recall, Precision, PR-AUC, Recall@capacidad y mÃ©todos para fijar el umbral Ã³ptimo y demostrar otros impactos\n",
        "Tomando el ejemplo del abandono estudiantil, suponiendo que el accuracy es del 98%.Esto me dice que el modelo  siempre va a predecir que NO deserta, pero no rescata a nadie (recall = 0). Accuracy no dice a quiÃ©n ayudaremos ni cuÃ¡nto ahorro/impacto logramos.\n",
        "AdemÃ¡s, accuracy:\n",
        "\n",
        "b) Â¿QuÃ© otras mÃ©tricas usarÃ­a y por quÃ©?  \n",
        "Recall (sensibilidad) de la clase â€œdesertaâ€  \n",
        "Mide cuÃ¡ntos desertores detectas. Es clave si el FN (no intervenir a quien sÃ­ desertarÃ¡) es costoso.  \n",
        "Precision (PPV)  \n",
        "Mide cuÃ¡ntos de los seÃ±alados realmente desertan. Importa si los recursos de intervenciÃ³n son limitados (evitar contactos inÃºtiles).  \n",
        "PR-AUC (Precisionâ€“Recall AUC)  \n",
        "Mejor que ROC-AUC en clases desbalanceadas; resume el desempeÃ±o en distintos umbrales.  \n",
        "CalibraciÃ³n (Brier score, curva de calibraciÃ³n)  \n",
        "Probabilidades bien calibradas permiten priorizar: 0.70 debe significar ~70% de riesgo. Vital para asignar becas, tutorÃ­as, llamadas.  \n",
        "Balanced accuracy / MCC  \n",
        "Alternativas robustas a accuracy bajo desbalance.  \n",
        "recall/paridad por carrera, campus, gÃ©nero, nivel socioeconÃ³mico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c60771",
      "metadata": {
        "id": "c1c60771"
      },
      "source": [
        "> Fin del cuadernillo. Los bloques en Python fueron agregados solo como apoyo y **no alteran tus respuestas**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
