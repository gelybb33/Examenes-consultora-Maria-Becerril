{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gelybb33/Examenes-consultora-Maria-Becerril/blob/main/Examen_DS_Maria_Becerril_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e051462",
      "metadata": {
        "id": "2e051462"
      },
      "source": [
        "# Examen DS Maria Becerril"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51491930",
      "metadata": {
        "id": "51491930"
      },
      "source": [
        "\n",
        "## 1) Teorema de Bayes: explicaci√≥n y ejemplo\n",
        "\n",
        "Explica con tus palabras el teorema de Bayes y da un ejemplo de c√≥mo lo aplicar√≠as en un problema de clasificaci√≥n.\n",
        "\n",
        "Probabilidad de un evento dado que ocurri√≥ otro o una serie de eventos\n",
        "\n",
        "\\(P(ùëó/ùíô)=(ùëÉ(ùëó)ùëÉ(ùíô|ùëó))/ùëÉ(ùíô)\\)\n",
        "\n",
        "\\(ùëÉ(ùíô|ùëó)=\\) Probabilidad de x dado que el evento j suceda  \n",
        "\\(P(ùëó/ùíô)=\\) Probabilidad de que j ocurra dado que x sucede  \n",
        "\\(P(x)=\\) Probabilidad de que x ocurra  \n",
        "\\(P(j)=\\) Probabilidad de que j ocurra  \n",
        "\n",
        "**Ejemplo Bayes:**  \n",
        "Queremos saber la probabilidad de que los enfermos de gripa e influenza puedan tener o no sintomas.\n",
        "\n",
        "P (y= sintomatico, x= Gripa & Influenza) = .6 \\*.5\\*.25 = .075  \n",
        "P (y= asintomatico, x= Gripa & Influenza) = .4 \\* .6 \\* .2 = .048  \n",
        "P(x= Gripa & Influenza) = .075 + .048 = .123  \n",
        "P (y= sintomatico, x= Gripa & Influenza) = .075 / .123 = .61  \n",
        "P (y= asintomatico, x= Gripa & Influenza) .048 / .123 = .39  \n",
        "\n",
        "Existe un 61% de que los enfermos de Gripa e Influenza tengan s√≠ntomas, y un 39% de que los enfermos de Gripa e Influenza sean asintom√°ticos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "754c7435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754c7435",
        "outputId": "d0ccf456-68bd-4ff2-ba34-87f462b43dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(y=sintom√°tico | x=gripa&influenza) = 0.61\n",
            "P(y=asintom√°tico | x=gripa&influenza) = 0.39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo bayes Python\n",
        "p_sym = 0.6\n",
        "p_gripa = 0.5\n",
        "p_infl = 0.25\n",
        "p_asym = 0.4\n",
        "p_gripa_alt = 0.6\n",
        "p_infl_alt = 0.2\n",
        "\n",
        "p_yx_sym = p_sym * p_gripa * p_infl      # 0.075\n",
        "p_yx_asym = p_asym * p_gripa_alt * p_infl_alt  # 0.048\n",
        "p_x = p_yx_sym + p_yx_asym               # 0.123\n",
        "\n",
        "post_sym = p_yx_sym / p_x\n",
        "post_asym = p_yx_asym / p_x\n",
        "\n",
        "print(\"P(y=sintom√°tico | x=gripa&influenza) =\", round(post_sym, 3))\n",
        "print(\"P(y=asintom√°tico | x=gripa&influenza) =\", round(post_asym, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b9bc10",
      "metadata": {
        "id": "c6b9bc10"
      },
      "source": [
        "\n",
        "## 2) Deserci√≥n universitaria con sensibilidad/especificidad\n",
        "\n",
        "**Planteamiento:** En una universidad, el 2% de los estudiantes desertan en el primer semestre. Un modelo de riesgo detecta correctamente a un desertor con probabilidad 0.9 (sensibilidad) y a un no desertor con probabilidad 0.8 (especificidad).  \n",
        "\n",
        "**a) ¬øCu√°l es la probabilidad de que un estudiante clasificado como desertor realmente lo sea?**\n",
        "\n",
        "Estamos buscando la tasa verdaderos positivos, siendo el desertor  \n",
        "P(cd|d) = .9  \n",
        "P(d)=.02  \n",
        "P(d¬¨) = .98  \n",
        "P(cd)= Probabilidad clasificado como desertor\n",
        "\n",
        "P(d|cd)= Probabilidad de un desertor dado que se clasifico como desertor  \n",
        "\\(P(d|cd)=(P(cd|d)P(d))/(P(cd‚îÇd)P(d)+ P(cd‚îÇd¬¨)P(d¬¨) )\\)\n",
        "\n",
        "\\(P(d‚îÇcd) =(.9 \\* .02)/((.9 \\* .02)+(.2 \\* .098) )= .018/.214\\)  \n",
        "**\\(P(d|cd) = 0.084\\)**\n",
        "\n",
        "**b) Interpretaci√≥n **\n",
        "Existe un 8.4% de probabilidad de que un estudiante que ha sido clasificado como desertor lo sea; es decir que, tomando como target a los desertores, la tasa de clasificaci√≥n de verdaderos positivas es muy baja. Aunque la sensibilidad (detecci√≥n correcta de desertores reales) y especificidad (detecci√≥n correcta de los que no desertan) del modelo (.9 & .8) son datos realmente altos. Aqu√≠ como opci√≥n no descartar√≠a el modelo, y propondr√≠a si bien ya no se puede aumentar la tasa de verdaderos positivos lo optar√≠a para obtener los falsos positivos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "80b72e1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80b72e1b",
        "outputId": "2e8b2457-e0c0-4e14-9a4e-1791bb0749c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPV (P(d=1|clasificado como desertor)) = 0.084\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo 2 desertores Python\n",
        "sens = 0.9      # TPR\n",
        "spec = 0.8      # TNR\n",
        "prev = 0.02     # prevalencia P(d=1)\n",
        "\n",
        "ppv = (sens*prev) / (sens*prev + (1-spec)*(1-prev))\n",
        "print(\"PPV (P(d=1|clasificado como desertor)) =\", round(ppv, 3))  # 0.084\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589aa562",
      "metadata": {
        "id": "589aa562"
      },
      "source": [
        "\n",
        "## 3) ¬øCu√°ndo usar a priori uniforme vs. estimarla con hist√≥rico?\n",
        "Cu√°ndo usar apriori uniforme?  \n",
        "Basandonos del concepto donde la a priori uniforme significa que asignamos la misma probabilidad a todos los valores posibles del par√°metro dentro de un rango definido. Por lo que se usa cuando no se tiene informaci√≥n previa. Tambi√©n se puede optar por su uso cuando el target se encuentra equilibrado esperas la misma probabilidad de resultado en cualquier valor que pueda tomar.\n",
        "\n",
        "Cuando conviene estimarla con informaci√≥n hist√≥rica?  \n",
        "Cuando se tiene informaci√≥n hist√≥rica representativa y verdadera se optar√≠a por estimarla, para estabilizar estimaciones, as√≠ mismo el hist√≥rico puede ayudar a entender fluctuaciones o eventos at√≠picos en la informaci√≥n que sean recurrentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1caa9843",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caa9843",
        "outputId": "33d1755e-fa85-4c49-82a5-046db7e0ab66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posterior media con prior uniforme  : 0.0294\n",
            "Posterior media con prior hist√≥rica : 0.0202\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo adicional (Python) ‚Äî actualizaci√≥n Beta-Binomial con prior uniforme vs. informada\n",
        "import numpy as np\n",
        "\n",
        "alpha_u, beta_u = 1, 1    # prior uniforme Beta(1,1)\n",
        "alpha_i, beta_i = 101, 4901  # prior hist√≥rica ~2% (ejemplo)\n",
        "\n",
        "obs_pos, obs_neg = 2, 98  # observaciones nuevas (ejemplo)\n",
        "\n",
        "post_u = (alpha_u+obs_pos, beta_u+obs_neg)\n",
        "post_i = (alpha_i+obs_pos, beta_i+obs_neg)\n",
        "\n",
        "mean_u = (post_u[0])/(post_u[0]+post_u[1])\n",
        "mean_i = (post_i[0])/(post_i[0]+post_i[1])\n",
        "\n",
        "print(\"Posterior media con prior uniforme  :\", round(mean_u, 4))\n",
        "print(\"Posterior media con prior hist√≥rica :\", round(mean_i, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e705cca2",
      "metadata": {
        "id": "e705cca2"
      },
      "source": [
        "\n",
        "## 4) K-Fold vs. LOO vs. Hold-out\n",
        "\n",
        "**KFOLD**:\n",
        "-Partes los datos en k, entrenas k veces validando cada fold y promedias al ultimo.\n",
        "-Tiene variantes con aplicaciones para grupos y series de tiempo\n",
        "-M√°s estable y costoso\n",
        "**LOO**:\n",
        "-Muestras muy peque√±as con varianza alta, puede tener costos computacionales altos\n",
        "-Cuando quieres minimizar el sesgo del estimador de error tomando en cuenta que tu varianza aumentara\n",
        "-No usarlo cuando el modelo es no lineal\n",
        "-Poco sesgo pero alta varianza\n",
        "**Hold-Out**:\n",
        "-Es r√°pido y para datasets grandes\n",
        "-Si te preocupa el efecto en la varianza puedes hacer multiples split y promedio para ponderarla\n",
        "-M√°s rapido pero ruidoso\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6190fa87",
      "metadata": {
        "id": "6190fa87"
      },
      "source": [
        "\n",
        "## 5) M√©tricas y mejora sin perder interpretabilidad. Tienes un modelo de clasificaci√≥n con las siguientes m√©tricas en validaci√≥n: - Accuracy: 92% - Precision (positiva): 50% - Recall (positiva): 20% a) ¬øQu√© problema est√°s observando en el modelo? b) ¬øQu√© estrategia usar√≠as para mejorar el desempe√±o sin perder interpretabilidad?\n",
        "Accuracy = 92%  \n",
        "Precision(+) = 50%  \n",
        "Recall(+) = 20%  \n",
        "Aunque en primera instancia tiene un accuracy alto, tenemos un 20% detectar los Verdaderos positivos, por lo que se tiene un 80% de detectar los Falsos negativos  \n",
        "La precisi√≥n 50 nos dice que la mitad de los casos que se marcaron como positivos realmente eran positivo\n",
        "\n",
        "2. ¬øC√≥mo mejoro sin perder interpretabilidad?  \n",
        "Como subir el recall, sin perder interpretabilidad?  \n",
        "Utilizar otra m√©trica de validaci√≥n adecuada como PR-AUC √°rea bajo la curva no accuracy. PR-AUC resume esa curva en un solo n√∫mero: cuanto m√°s alto, mejor el modelo para mantener alta precisi√≥n cuando empujas el recall.  \n",
        "Para dar m√°s peso a la clase positiva usamos class_weight=\"balanced\".  \n",
        "‚Ä¢  Ajuste de umbral (post-entrenamiento): no uses 0.5 por defecto.  \n",
        "‚Ä¢  Bajar el umbral : etiquetas m√°s casos como positivos ‚áí sube el recall (TPR) y tambi√©n suben los FP (baja la precisi√≥n, sube FPR, baja especificidad).  \n",
        "‚Ä¢  Subir el umbral : etiquetas menos casos como positivos ‚áí baja el recall, pero suele subir la precisi√≥n. El umbral es tu palanca directa sobre el recall. Bajar el umbral aumenta recall (a costa de m√°s FP); elige el punto operativo con una regla expl√≠cita\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee94948",
      "metadata": {
        "id": "3ee94948"
      },
      "source": [
        "\n",
        "## 6) AUC=0.78 e umbral √≥ptimo por costos. Imagina que entrenaste un modelo de regresi√≥n log√≠stica y obtienes una curva ROC con un AUC de 0.78. a) Qu√© significa este valor en t√©rminos de discriminaci√≥n.\n",
        "\n",
        "Qu√© significa AUC = 0.78?  \n",
        "Como sabemos el ROC‚ÄìAUC en log√≠stica mide qu√© tan bien el modelo ordena positivos por encima de negativos para todos los umbrales. Existe un 78% de probabilidad de que un positivo real reciba un score mayor que un negativo aleatorio. Tomando que el valor aleatorio por default, es un 50% de probabilidad de que discrimine un positivo real de un negativo, interpreto que esta sobre el aleatorio y es una buena regla.\n",
        "\n",
        "**b) Umbral √≥ptimo por costos (original):**  \n",
        "Minimiza el costo esperado en validaci√≥n usando TPR/FPR para cada umbral:  \n",
        "\\(Costo(œÑ) = œÄ¬∑C_{FN}¬∑(1‚àíTPR(œÑ)) + (1‚àíœÄ)¬∑C_{FP}¬∑FPR(œÑ)\\)  \n",
        "œÄ = prevalencia (P(y=1)) medida en tu val original  \n",
        "Recorres los umbrales, calculas TPR/FPR y eliges el œÑ que minimiza ese costo.  \n",
        "Equivalente geom√©trico en la ROC: usa iso-cost lines con pendiente  \n",
        "\\(m = (C_{FP}¬∑(1‚àíœÄ)) / (C_{FN}¬∑œÄ)\\)\n",
        "\n",
        "**Mini-ejemplo num√©rico (original, calibrado):**\n",
        "Sup√≥n probabilidades en validaci√≥n:  \n",
        "\\(\\hat p = [0.85, 0.62, 0.40, 0.15, 0.08, 0.03]\\)  \n",
        "y reales: \\(y = [1, 1, 0, 1, 0, 0]\\)  \n",
        "Costos: \\(C_{FN}=5, C_{FP}=1 ‚áí œÑ^* = 1/(1+5)=0.1667\\)  \n",
        "Predices 1 si \\(\\hat p ‚â• 0.1667\\) ‚áí predicciones: [1,1,1,0,0,0]  \n",
        "Errores: FP: elemento 3 ‚áí 1 FP; FN: elemento 4 ‚áí 1 FN  \n",
        "Costo total = 6  \n",
        "\n",
        "Si usaras por defecto œÑ=0.5 ‚áí predicciones [1,1,0,0,0,0] ‚áí FP: 0; FN: 1 ‚áí Costo total = 5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "108adaeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "108adaeb",
        "outputId": "aa1971aa-c681-47dc-ec12-1465560ad7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Costo en œÑ*‚âà0.1667: 6 | FP, FN = 1 1\n",
            "Costo en œÑ=0.5    : 5 | FP, FN = 0 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo en Python ‚Äî calcular el costo del ejemplo original en ambos umbrales\n",
        "import numpy as np\n",
        "\n",
        "p = np.array([0.85, 0.62, 0.40, 0.15, 0.08, 0.03])\n",
        "y = np.array([1,1,0,1,0,0])\n",
        "C_FN, C_FP = 5, 1\n",
        "tau = 1/(1+C_FN)  # 0.1667\n",
        "\n",
        "def cost_at(t):\n",
        "    yhat = (p >= t).astype(int)\n",
        "    FP = int(((yhat==1)&(y==0)).sum())\n",
        "    FN = int(((yhat==0)&(y==1)).sum())\n",
        "    return C_FN*FN + C_FP*FP, FP, FN\n",
        "\n",
        "c1, fp1, fn1 = cost_at(tau)\n",
        "c2, fp2, fn2 = cost_at(0.5)\n",
        "\n",
        "print(\"Costo en œÑ*‚âà0.1667:\", c1, \"| FP, FN =\", fp1, fn1)\n",
        "print(\"Costo en œÑ=0.5    :\", c2, \"| FP, FN =\", fp2, fn2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496cc3a1",
      "metadata": {
        "id": "496cc3a1"
      },
      "source": [
        "\n",
        "## 7) Regresi√≥n lineal m√∫ltiple vs. regularizada (Ridge/Lasso)\n",
        "1) Regresi√≥n lineal m√∫ltiple (OLS)  \n",
        "Estimadores insesgados bajo supuestos cl√°sicos (linealidad, homocedasticidad, no multicolinealidad fuerte).  \n",
        "Varianza alta si hay pocas observaciones, muchos predictores o multicolinealidad.  \n",
        "Poca colinealidad  \n",
        "Se usa cuando tienes pocos predictores, bien elegidos, con baja colinealidad, y un n grande.\n",
        "\n",
        "2) Regresi√≥n regularizada  \n",
        "**Ridge (L2)**  \n",
        "Efecto: Busca disminuir coeficientes a 0, sin llegar a 0.  \n",
        "Reduce varianza y mejora generalizaci√≥n.  \n",
        "Excelente con muchos predictores correlacionados (estabiliza al ‚Äúrepartir‚Äù peso entre ellos).  \n",
        "Se puede usar cuando se tiene una correlaci√≥n alta entre variables y no puedes decidir que variable dejar o quieres usar varias variable correlacioandas  \n",
        "Quieres estabilidad m√°s que selecci√≥n estricta de variables.\n",
        "\n",
        "**Lasso (L1)**  \n",
        "√ötil cuando hay muchos predictores irrelevantes.  \n",
        "Con predictores muy correlacionados, Lasso tiende a elegir uno y descartar el resto  \n",
        "Se usa cuando queremos reducir el conjunto de variables a un subconjunto mas peque√±o.  \n",
        "Tambi√©n si comportamientos raros y muchos de ellos son ruido\n",
        "\n",
        "**En Resumen:**  \n",
        "- Regresi√≥n m√∫ltiple: pocas variables, sin multicolinealidad (p.ej., afluencia a restaurante).  \n",
        "- Lasso: dataset grande para seleccionar variables (ej. INEGI).  \n",
        "- Ridge: variables correlacionadas (estatura, peso, edad en nado).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplos de cuando usaria y quetipo de Regresion Multiple**:\n",
        "##Ejemplo regresi√≥n multiple:\n",
        "Tienes pocas variables, no hay multicolinealidad, Lo puedes usar para predecir las entradas de personas a un restaurante, usando si tienen hijos, si comen o cenan (variables que no esten correlacionadas y un data set chico ..)\n",
        "##Ejemplo regresi√≥n lasso:\n",
        "Cuando tienes data sets mas grandes y quieres discriminar por las que contienen mayor informaci√≥n para el modelo, ejemplo tienes 100 variables en un base del inegi para saber el nivel de endeudamiento, con lasso puedes discriminar esto.\n",
        "##Ejemplo regresi√≥n Ridge:\n",
        "Quieres conocer por que en una competencia de nado los participantes son mas veloces, y tienes variables como estatura, peso, edad que generalmente est√°n correlacionadas, con ridge puedes dejarlas en el modelo ..\n"
      ],
      "metadata": {
        "id": "dumsZperVYHU"
      },
      "id": "dumsZperVYHU"
    },
    {
      "cell_type": "markdown",
      "id": "6d21e68d",
      "metadata": {
        "id": "6d21e68d"
      },
      "source": [
        "\n",
        "## 8) Error en train vs. validation. Sup√≥n que al ajustar un modelo de regresi√≥n lineal obtienes: - Training error = 0.02 - Validation error = 0.30\n",
        "a) ¬øQu√© est√° ocurriendo?  \n",
        "Con training error = 0.02 y validation error = 0.30 estamos diciendo que el modleo comete un error del 2% con los datos, √≥sea casi 0 error y luego el error de la validaci√≥n aumenta un 30%, por lo que lo traduzco que tiene excelente interpretaci√≥n para el set de entrenamiento, lo que ocasiono una mala interpretaci√≥n para el set de validaci√≥n o general.\n",
        "\n",
        "b) ¬øQu√© acciones tomar para corregirlo?  \n",
        "Revisar que no haya una variable que me este generando ruido, artificial, o algun input realizado anteriormente.  \n",
        "‚Ä¢  Usar un modelo m√°s simple (menos par√°metros, regularizaci√≥n).  \n",
        "‚Ä¢  Aumentar datos de entrenamiento.  \n",
        "‚Ä¢  Aplicar t√©cnicas como cross-validation, early stopping, dropout (en redes), etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8765653c",
      "metadata": {
        "id": "8765653c"
      },
      "source": [
        "\n",
        "## 9) Trade-off sesgo‚Äìvarianza. Define y ejemplifica el trade-off entre sesgo y varianza. Da un ejemplo aplicado a un modelo predictivo en educaci√≥n.\n",
        "Qu√© es el trade-off sesgo‚Äìvarianza?  \n",
        "El sesgo es el error sistem√°tico por usar un modelo demasiado simple o mal especificado (subajuste).Y la varianza es que tanto pueden cambiar las predicciones si reentrenas con diferentes muestras; suele crecer con modelos muy complejos.  \n",
        "El trade-off entre sesgo y varianza consiste en mantener un equilibrio ya que si bajas el sesgo se sube la varianza por lo que el objetivo es buscar un intermedio.\n",
        "\n",
        "Se√±ales pr√°cticas  \n",
        "subajuste: alto sesgo, error alto en train y valid; curvas de aprendizaje planas.  \n",
        "sobreajuste: alta varianza, error train bajo, pero  valid notablemente peor.\n",
        "\n",
        "**Ejemplo original (educaci√≥n):**\n",
        "Supongamos que queremos predecir si un estudiante aprobar√° un curso en funci√≥n de:\n",
        "‚Ä¢\tHoras de estudio por semana\n",
        "‚Ä¢\tAsistencia a clase\n",
        "‚Ä¢\tEntrega de tareas\n",
        "##Caso 1: Modelo con alto sesgo\n",
        "Usamos una regresi√≥n lineal con solo una variable (horas de estudio).\n",
        "‚Ä¢\tEl modelo depende de las horas de estudio unicamnete para predecir, dejando afuera m√°s variables\n",
        "‚Ä¢\tResultado: hace predicciones muy generales\n",
        "‚Ä¢\tProblema: subajuste ‚Üí muchas predicciones incorrectas.\n",
        "##Caso 2: Modelo con alta varianza\n",
        "Usamos un √°rbol de decisi√≥n muy profundo que memoriza cada combinaci√≥n de horas, asistencia y tareas. Osea se esta sobreajustando y repitiendo muchas veces la misma informaci√≥n.\n",
        "‚Ä¢\tEn el train, predice perfecto.\n",
        "‚Ä¢\tPero en test, falla mucho porque memoriz√≥ los datos en lugar de aprender el patr√≥n general.\n",
        "‚Ä¢\tProblema: sobreajuste ‚Üí baja generalizaci√≥n.\n",
        "##Caso Ideal con Varianza y sesgo ajustado\n",
        "Usamos un √°rbol de decisi√≥n podado o un Random Forest con pocos niveles.\n",
        "‚Ä¢\tUsando todas las variables para interpretar (horas de estudio + asistencia + tareas)\n",
        "‚Ä¢\tResultado esperado: error bajo en train y en valid/test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69829e80",
      "metadata": {
        "id": "69829e80"
      },
      "source": [
        "\n",
        "## 10) Est√°s construyendo un modelo para predecir el abandono estudiantil. El VP de Operaciones te dice que ‚Äúlo √∫nico que importa es el accuracy‚Äù.\n",
        "** a) ¬øQu√© le responder√≠as? **\n",
        "Si bien el accuracy es muy √∫til para la predicci√≥n del modelo, le explicar√≠a que existen otras m√©tricas orientadas a decisi√≥n como  Recall, Precision, PR-AUC, Recall@capacidad y m√©todos para fijar el umbral √≥ptimo y demostrar otros impactos.\n",
        "Tomando el ejemplo del abandono estudiantil, suponiendo que el accuracy es del 98%.Esto me dice que el modelo  siempre va a predecir que NO deserta, pero no rescata a nadie (recall = 0). Accuracy no dice a qui√©n ayudaremos ni cu√°nto ahorro/impacto logramos.\n",
        "\n",
        "**b) ¬øQu√© otras m√©tricas usar√≠a y por qu√©?  **\n",
        "Recall (sensibilidad) de la clase ‚Äúdeserta‚Äù  \n",
        "Mide cu√°ntos desertores detectas. Es clave si el FN (no intervenir a quien s√≠ desertar√°) es costoso.  \n",
        "Precision (PPV)  \n",
        "Mide cu√°ntos de los se√±alados realmente desertan. Importa si los recursos de intervenci√≥n son limitados (evitar contactos in√∫tiles).  \n",
        "PR-AUC (Precision‚ÄìRecall AUC)  \n",
        "Mejor que ROC-AUC en clases desbalanceadas; resume el desempe√±o en distintos umbrales.  \n",
        "Calibraci√≥n (Brier score, curva de calibraci√≥n)  \n",
        "Probabilidades bien calibradas permiten priorizar: 0.70 debe significar ~70% de riesgo. Vital para asignar becas, tutor√≠as, llamadas.  \n",
        "Balanced accuracy / MCC  \n",
        "Alternativas robustas a accuracy bajo desbalance.  \n",
        "recall/paridad por carrera, campus, g√©nero, nivel socioecon√≥mico.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
