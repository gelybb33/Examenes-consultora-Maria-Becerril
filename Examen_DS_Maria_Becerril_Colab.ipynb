{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gelybb33/Examenes-Gely/blob/main/Examen_DS_Maria_Becerril_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e051462",
      "metadata": {
        "id": "2e051462"
      },
      "source": [
        "# Examene DS  ‚Äì Maria Becerril Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51491930",
      "metadata": {
        "id": "51491930"
      },
      "source": [
        "\n",
        "## 1) Teorema de Bayes: explicaci√≥n y ejemplo\n",
        "\n",
        "Explica con tus palabras el teorema de Bayes y da un ejemplo de c√≥mo lo aplicar√≠as en un problema de clasificaci√≥n.\n",
        "\n",
        "**Respuesta original :**\n",
        "\n",
        "Probabilidad de un evento dado que ocurri√≥ otro o una serie de eventos\n",
        "\n",
        "\\(P(ùëó/ùíô)=(ùëÉ(ùëó)ùëÉ(ùíô|ùëó))/ùëÉ(ùíô)\\)\n",
        "\n",
        "\\(ùëÉ(ùíô|ùëó)=\\) Probabilidad de x dado que el evento j suceda  \n",
        "\\(P(ùëó/ùíô)=\\) Probabilidad de que j ocurra dado que x sucede  \n",
        "\\(P(x)=\\) Probabilidad de que x ocurra  \n",
        "\\(P(j)=\\) Probabilidad de que j ocurra  \n",
        "\n",
        "**Ejemplo:**  \n",
        "Queremos saber la probabilidad de que los enfermos de gripa e influenza puedan tener o no sintomas.\n",
        "\n",
        "P (y= sintomatico, x= Gripa & Influenza) = .6 \\*.5\\*.25 = .075  \n",
        "P (y= asintomatico, x= Gripa & Influenza) = .4 \\* .6 \\* .2 = .048  \n",
        "P(x= Gripa & Influenza) = .075 + .048 = .123  \n",
        "P (y= sintomatico, x= Gripa & Influenza) = .075 / .123 = .61  \n",
        "P (y= asintomatico, x= Gripa & Influenza) .048 / .123 = .39  \n",
        "\n",
        "Existe un 61% de que los enfermos de Gripa e Influenza tengan s√≠ntomas, y un 39% de que los enfermos de Gripa e Influenza sean asintom√°ticos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "754c7435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754c7435",
        "outputId": "807bafb8-9bdf-4af7-fe6a-cb9f09c2edc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(y=sintom√°tico | x=gripa&influenza) = 0.61\n",
            "P(y=asintom√°tico | x=gripa&influenza) = 0.39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ejemplo  - BAYES\n",
        "p_sym = 0.6\n",
        "p_gripa = 0.5\n",
        "p_infl = 0.25\n",
        "p_asym = 0.4\n",
        "p_gripa_alt = 0.6\n",
        "p_infl_alt = 0.2\n",
        "\n",
        "p_yx_sym = p_sym * p_gripa * p_infl      # 0.075\n",
        "p_yx_asym = p_asym * p_gripa_alt * p_infl_alt  # 0.048\n",
        "p_x = p_yx_sym + p_yx_asym               # 0.123\n",
        "\n",
        "post_sym = p_yx_sym / p_x\n",
        "post_asym = p_yx_asym / p_x\n",
        "\n",
        "print(\"P(y=sintom√°tico | x=gripa&influenza) =\", round(post_sym, 3))\n",
        "print(\"P(y=asintom√°tico | x=gripa&influenza) =\", round(post_asym, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b9bc10",
      "metadata": {
        "id": "c6b9bc10"
      },
      "source": [
        "\n",
        "## 2) Deserci√≥n universitaria con sensibilidad/especificidad\n",
        "\n",
        " En una universidad, el 2% de los estudiantes desertan en el primer semestre. Un modelo de riesgo detecta correctamente a un desertor con probabilidad 0.9 (sensibilidad) y a un no desertor con probabilidad 0.8 (especificidad).  \n",
        "\n",
        "**a) ¬øCu√°l es la probabilidad de que un estudiante clasificado como desertor realmente lo sea?**\n",
        "\n",
        "Estamos buscando la tasa verdaderos positivos, siendo el desertor  \n",
        "P(cd|d) = .9  \n",
        "P(d)=.02  \n",
        "P(d¬¨) = .98  \n",
        "P(cd)= Probabilidad clasificado como desertor\n",
        "\n",
        "P(d|cd)= Probabilidad de un desertor dado que se clasifico como desertor  \n",
        "\\(P(d|cd)=(P(cd|d)P(d))/(P(cd‚îÇd)P(d)+ P(cd‚îÇd¬¨)P(d¬¨) )\\)\n",
        "\n",
        "\\(P(d‚îÇcd) =(.9 \\* .02)/((.9 \\* .02)+(.2 \\* .098) )= .018/.214\\)  \n",
        "**\\(P(d|cd) = 0.084\\)**\n",
        "\n",
        "**b) Interpretaci√≥n :**  \n",
        "Existe un 8.4% de probabilidad de que un estudiante que ha sido clasificado como desertor lo sea; es decir que, tomando como target a los desertores, la tasa de clasificaci√≥n de verdaderos positivas es muy baja. Aunque la sensibilidad (detecci√≥n correcta de desertores reales) y especificidad (detecci√≥n correcta de los que no desertan) del modelo (.9 & .8) son datos realmente altos. Aqu√≠ como opci√≥n no descartar√≠a el modelo, y propondr√≠a si bien ya no se puede aumentar la tasa de verdaderos positivos lo optar√≠a para obtener los falsos positivos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589aa562",
      "metadata": {
        "id": "589aa562"
      },
      "source": [
        "\n",
        "## 3) ¬øCu√°ndo usar a priori uniforme vs. estimarla con hist√≥rico?\n",
        "\n",
        "Cu√°ndo usar apriori uniforme?  \n",
        "Basandonos del concepto donde la a priori uniforme significa que asignamos la misma probabilidad a todos los valores posibles del par√°metro dentro de un rango definido. Por lo que se usa cuando no se tiene informaci√≥n previa. Tambi√©n se puede optar por su uso cuando el target se encuentra equilibrado esperas la misma probabilidad de resultado en cualquier valor que pueda tomar.\n",
        "\n",
        "Cuando conviene estimarla con informaci√≥n hist√≥rica?  \n",
        "Cuando se tiene informaci√≥n hist√≥rica representativa y verdadera se optar√≠a por estimarla, para estabilizar estimaciones, as√≠ mismo el hist√≥rico puede ayudar a entender fluctuaciones o eventos at√≠picos en la informaci√≥n que sean recurrentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1caa9843",
      "metadata": {
        "id": "1caa9843"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ejemplo adicional  Beta-Binomial con prior uniforme vs. informada\n",
        "import numpy as np\n",
        "\n",
        "alpha_u, beta_u = 1, 1    # prior uniforme Beta(1,1)\n",
        "alpha_i, beta_i = 101, 4901  # prior hist√≥rica su media usando los par√°metros ~2%\n",
        "\n",
        "obs_pos, obs_neg = 2, 98  # observaciones nuevas\n",
        "\n",
        "post_u = (alpha_u+obs_pos, beta_u+obs_neg)\n",
        "post_i = (alpha_i+obs_pos, beta_i+obs_neg)\n",
        "\n",
        "mean_u = (post_u[0])/(post_u[0]+post_u[1])\n",
        "mean_i = (post_i[0])/(post_i[0]+post_i[1])\n",
        "\n",
        "print(\"Posterior media con prior uniforme  :\", round(mean_u, 4))\n",
        "print(\"Posterior media con prior hist√≥rica :\", round(mean_i, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e705cca2",
      "metadata": {
        "id": "e705cca2"
      },
      "source": [
        "\n",
        "## 4) K-Fold vs. LOO vs. Hold-out\n",
        "K-fold: Partes los datos en k, entrenas k veces validando cada fold y promedias al ultimo.\n",
        "mantener la proporcion de k-folds en los que se divide\n",
        "Tiene variantes con aplicaciones para grupos y series d etiempo\n",
        "M√°s estable y costoso.\n",
        "LOO: Muestras muy peque√±as con varianza alta, puede tener costos computacionales altos\n",
        "Quieres minimizar el sesgo del estimador de error tomando en cuenta que tu varianza aumentara\n",
        "No usarlo cuando el modelo es no lineal.\n",
        "Poco sesgo pero alta varianza.\n",
        "Hold-out: Es r√°pido y para datasets grandes.\n",
        "Hacer estratificacion para clasificaci√≥n desbalanceada.\n",
        "Si te preocupa el efecto en la varianza puedes hacer multiples split y promedio para ponderarla.\n",
        "M√°s rapido pero ruidoso.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6190fa87",
      "metadata": {
        "id": "6190fa87"
      },
      "source": [
        "\n",
        "## 5) M√©tricas y mejora sin perder interpretabilidad\n",
        "\n",
        "Accuracy = 92%  \n",
        "Precision(+) = 50%  \n",
        "Recall(+) = 20% Los Falsos negativos  \n",
        "Aunque en primera instancia tiene un accuracy alto, tenemos un 20% detectar los Verdaderos positivos, por lo que se tiene un 80% de detectar los Falsos negativos  \n",
        "La precisi√≥n 50 nos dice que la mitad de los casos que se marcaron como positivos realmente eran positivo\n",
        "\n",
        "2. ¬øC√≥mo mejoro sin perder interpretabilidad?  \n",
        "Como subir el recall, sin perder interpretabilidad?  \n",
        "Utilizar otra m√©trica de validaci√≥n adecuada como PR-AUC √°rea bajo la curva no accuracy. PR-AUC resume esa curva en un solo n√∫mero: cuanto m√°s alto, mejor el modelo para mantener alta precisi√≥n cuando empujas el recall.  \n",
        "Para dar m√°s peso a la clase positiva usamos class_weight=\"balanced\".  \n",
        "‚Ä¢  Ajuste de umbral (post-entrenamiento): no uses 0.5 por defecto.  \n",
        "‚Ä¢  Bajar el umbral : etiquetas m√°s casos como positivos ‚áí sube el recall (TPR) y tambi√©n suben los FP (baja la precisi√≥n, sube FPR, baja especificidad).  \n",
        "‚Ä¢  Subir el umbral : etiquetas menos casos como positivos ‚áí baja el recall, pero suele subir la precisi√≥n. El umbral es tu palanca directa sobre el recall. Bajar el umbral aumenta recall (a costa de m√°s FP); elige el punto operativo con una regla expl√≠cita\n",
        "\n",
        "Re-muestreo o Resampling: Al re-balancear el train (haciendo la clase positiva menos rara), el modelo ‚Äúve‚Äù m√°s ejemplos positivos (o equivalentes ponderados) y baja el umbral interno para etiquetar 1 ‚áí detecta m√°s verdaderos positivos ‚áí ‚Üë recall (aunque suele bajar algo la precisi√≥n).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee94948",
      "metadata": {
        "id": "3ee94948"
      },
      "source": [
        "\n",
        "## 6) Imagina que entrenaste un modelo de regresi√≥n log√≠stica y obtienes una curva ROC con un AUC de 0.78. a) Qu√© significa este valor en t√©rminos de discriminaci√≥n.\n",
        "\n",
        "Qu√© significa AUC = 0.78?  \n",
        "Como sabemos el ROC‚ÄìAUC en log√≠stica mide qu√© tan bien el modelo ordena positivos por encima de negativos para todos los umbrales. Existe un 78% de probabilidad de que un positivo real reciba un score mayor que un negativo aleatorio. Tomando que el valor aleatorio por default, es un 50% de probabilidad de que discrimine un positivo real de un negativo, interpreto que esta sobre el aleatorio y es una buena regla.\n",
        "\n",
        "**b) Umbral √≥ptimo por costos :**  \n",
        "Minimiza el costo esperado en validaci√≥n usando TPR/FPR para cada umbral:  \n",
        "\\(Costo(œÑ) = œÄ¬∑C_{FN}¬∑(1‚àíTPR(œÑ)) + (1‚àíœÄ)¬∑C_{FP}¬∑FPR(œÑ)\\)  \n",
        "œÄ = prevalencia (P(y=1)) medida en tu val original  \n",
        "Recorres los umbrales, calculas TPR/FPR y eliges el œÑ que minimiza ese costo.  \n",
        "Equivalente geom√©trico en la ROC: usa iso-cost lines con pendiente  \n",
        "\\(m = (C_{FP}¬∑(1‚àíœÄ)) / (C_{FN}¬∑œÄ)\\)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496cc3a1",
      "metadata": {
        "id": "496cc3a1"
      },
      "source": [
        "\n",
        "## 7) Regresi√≥n lineal m√∫ltiple vs. regularizada (Ridge/Lasso)\n",
        "\n",
        "1) Regresi√≥n lineal m√∫ltiple (OLS)  \n",
        "Estimadores insesgados bajo supuestos cl√°sicos (linealidad, homocedasticidad, no multicolinealidad fuerte).  \n",
        "Varianza alta si hay pocas observaciones, muchos predictores o multicolinealidad.  \n",
        "Poca colinealidad  \n",
        "Se usa cuando tienes pocos predictores, bien elegidos, con baja colinealidad, y un n grande.\n",
        "\n",
        "2) Regresi√≥n regularizada  \n",
        "**Ridge (L2)**  \n",
        "Efecto: Busca disminuir coeficientes a 0, sin llegar a 0.  \n",
        "Reduce varianza y mejora generalizaci√≥n.  \n",
        "Excelente con muchos predictores correlacionados (estabiliza al ‚Äúrepartir‚Äù peso entre ellos).  \n",
        "Se puede usar cuando se tiene una correlaci√≥n alta entre variables y no puedes decidir que variable dejar o quieres usar varias variable correlacioandas  \n",
        "Quieres estabilidad m√°s que selecci√≥n estricta de variables.\n",
        "\n",
        "**Lasso (L1)**  \n",
        "√ötil cuando hay muchos predictores irrelevantes.  \n",
        "Con predictores muy correlacionados, Lasso tiende a elegir uno y descartar el resto  \n",
        "Se usa cuando queremos reducir el conjunto de variables a un subconjunto mas peque√±o.  \n",
        "Tambi√©n si comportamientos raros y muchos de ellos son ruido\n",
        "\n",
        "**Ejemplos:**  \n",
        "##Ejemplo regresi√≥n multiple:\n",
        "Tienes pocas variables, no hay multicolinealidad, Lo puedes usar para predecir las entradas de personas a un restaurante, usando si tienen hijos, si comen o cenan (variables que no esten correlacionadas y un data set chico ..)\n",
        "##Ejemplo regresi√≥n lasso:\n",
        "Cuando tienes data sets mas grandes y quieres discriminar por las que contienen mayor informaci√≥n para el modelo, ejemplo tienes 100 variables en un base del inegi para saber el nivel de endeudamiento, con lasso puedes discriminar esto.\n",
        "##Ejemplo regresi√≥n Ridge:\n",
        "Quieres conocer por que en una competencia de nado los participantes son mas veloces, y tienes variables como estatura, peso, edad que generalmente est√°n correlacionadas, con ridge puedes dejarlas en el modelo ..\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d21e68d",
      "metadata": {
        "id": "6d21e68d"
      },
      "source": [
        "\n",
        "## 8) Error en train vs. validation\n",
        "a) ¬øQu√© est√° ocurriendo?  \n",
        "Con training error = 0.02 y validation error = 0.30 estamos diciendo que el modleo comete un error del 2% con los datos, √≥sea casi 0 error y luego el error de la validaci√≥n aumenta un 30%, por lo que lo traduzco que tiene excelente interpretaci√≥n para el set de entrenamiento, lo que ocasiono una mala interpretaci√≥n para el set de validaci√≥n o general.\n",
        "\n",
        "b) ¬øQu√© acciones tomar para corregirlo?  \n",
        "Revisar que no haya una variable que me este generando ruido, artificial, o algun input realizado anteriormente.  \n",
        "‚Ä¢  Usar un modelo m√°s simple (menos par√°metros, regularizaci√≥n).  \n",
        "‚Ä¢  Aumentar datos de entrenamiento.  \n",
        "‚Ä¢  Aplicar t√©cnicas como cross-validation, early stopping, dropout (en redes), etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8765653c",
      "metadata": {
        "id": "8765653c"
      },
      "source": [
        "\n",
        "## 9) Trade-off sesgo‚Äìvarianza\n",
        "\n",
        "Qu√© es el trade-off sesgo‚Äìvarianza?  \n",
        "El sesgo es el error sistem√°tico por usar un modelo demasiado simple o mal especificado (subajuste). Y la varianza es que tanto pueden cambiar las predicciones si reentrenas con diferentes muestras; suele crecer con modelos muy complejos.  \n",
        "El trade-off entre sesgo y varianza consiste en mantener un equilibrio ya que si bajas el sesgo se sube la varianza por lo que el objetivo es buscar un intermedio.\n",
        "\n",
        "Se√±ales pr√°cticas  \n",
        "subajuste: alto sesgo, error alto en train y valid; curvas de aprendizaje planas.  \n",
        "sobreajuste: alta varianza, error train bajo, pero  valid notablemente peor.\n",
        "\n",
        "**Ejemplo  (educaci√≥n):**  \n",
        "Supongamos que queremos predecir si un estudiante aprobar√° un curso en funci√≥n de:\n",
        "‚Ä¢\tHoras de estudio por semana\n",
        "‚Ä¢\tAsistencia a clase\n",
        "‚Ä¢\tEntrega de tareas\n",
        "**Caso 1: Modelo con alto sesgo**\n",
        "Usamos una regresi√≥n lineal con solo una variable (horas de estudio).\n",
        "‚Ä¢\tEl modelo depende de las horas de estudio unicamnete para predecir, dejando afuera m√°s variables\n",
        "‚Ä¢\tResultado: hace predicciones muy generales\n",
        "‚Ä¢\tProblema: subajuste ‚Üí muchas predicciones incorrectas.\n",
        "**Caso 2: Modelo con alta varianza**\n",
        "Usamos un √°rbol de decisi√≥n muy profundo que memoriza cada combinaci√≥n de horas, asistencia y tareas. Osea se esta sobreajustando y repitiendo muchas veces la misma informaci√≥n.\n",
        "‚Ä¢\tEn el train, predice perfecto.\n",
        "‚Ä¢\tPero en test, falla mucho porque memoriz√≥ los datos en lugar de aprender el patr√≥n general.\n",
        "‚Ä¢\tProblema: sobreajuste ‚Üí baja generalizaci√≥n.\n",
        "**Caso Ideal con Varianza y sesgo ajustado**\n",
        "Usamos un √°rbol de decisi√≥n podado o un Random Forest con pocos niveles.\n",
        "‚Ä¢\tUsando todas las variables para interpretar (horas de estudio + asistencia + tareas)\n",
        "‚Ä¢\tResultado esperado: error bajo en train y en valid/test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69829e80",
      "metadata": {
        "id": "69829e80"
      },
      "source": [
        "\n",
        "## 10) Solo accuracy vs. m√©tricas orientadas a decisi√≥n\n",
        "\n",
        "Si bien el accuracy es muy √∫til para la predicci√≥n del modelo, le explicar√≠a que existen otras m√©tricas orientadas a decisi√≥n como  Recall, Precision, PR-AUC, Recall@capacidad y m√©todos para fijar el umbral √≥ptimo y demostrar otros impactos\n",
        "Tomando el ejemplo del abandono estudiantil, suponiendo que el accuracy es del 98%.Esto me dice que el modelo  siempre va a predecir que NO deserta, pero no rescata a nadie (recall = 0). Accuracy no dice a qui√©n ayudaremos ni cu√°nto ahorro/impacto logramos.\n",
        "Adem√°s, accuracy:\n",
        "\n",
        "b) ¬øQu√© otras m√©tricas usar√≠a y por qu√©?  \n",
        "Recall (sensibilidad) de la clase ‚Äúdeserta‚Äù  \n",
        "Mide cu√°ntos desertores detectas. Es clave si el FN (no intervenir a quien s√≠ desertar√°) es costoso.  \n",
        "Precision (PPV)  \n",
        "Mide cu√°ntos de los se√±alados realmente desertan. Importa si los recursos de intervenci√≥n son limitados (evitar contactos in√∫tiles).  \n",
        "PR-AUC (Precision‚ÄìRecall AUC)  \n",
        "Mejor que ROC-AUC en clases desbalanceadas; resume el desempe√±o en distintos umbrales.  \n",
        "Calibraci√≥n (Brier score, curva de calibraci√≥n)  \n",
        "Probabilidades bien calibradas permiten priorizar: 0.70 debe significar ~70% de riesgo. Vital para asignar becas, tutor√≠as, llamadas.  \n",
        "Balanced accuracy / MCC  \n",
        "Alternativas robustas a accuracy bajo desbalance.  \n",
        "recall/paridad por carrera, campus, g√©nero, nivel socioecon√≥mico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c60771",
      "metadata": {
        "id": "c1c60771"
      },
      "source": [
        
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
